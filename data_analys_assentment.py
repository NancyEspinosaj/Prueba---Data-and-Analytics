# -*- coding: utf-8 -*-
"""Data Analys- Assentment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Upn5YXoXbvhCqeESvDBFOJSfdkhoxWUq

# **ASSESSMENT CARGOS ANALÍTICOS**

##CASO DE CONSULTORIA

Suponga que la data que proces´o anteriormente pertenece a una empresa que
vende neveras portatiles. Haga un modelo que explique las ventas a trav´es de las variables de medios incluidas en los archivos adjuntos. Incluya otras variables que considere relevantes o que pueden afectar a las ventas de una compa˜nia que vende neveras portatiles.
Adicionalmente, incluya un documento en el que explique su modelo e interprete los resultados.
"""

# Commented out IPython magic to ensure Python compatibility.
# ========== Librerias ===============================
import numpy as np
import pandas as pd
from sklearn import preprocessing
from numpy.core.numeric import NaN
!pip install fitter
from fitter import Fitter

import matplotlib.pyplot as plt
# % matplotlib inline
from matplotlib import style
import seaborn as sns


#=================== ingresar la ruta de archivo CSV ==========================
data = pd.read_csv('/text.txt', sep=";")
df = pd.DataFrame(data)
df

"""### Exploracion de datos (Fase de comprension de datos)
*En esta seccion se muestra un analisis descriptivo inicial de los datos del caso de estudio, jusnto con los primeros pasos de limpieza de datos. Para el analisis se realizaron algunas agrupaciones con el fin de identificar correlacion entre datos.*
"""

uniqueValues = df['Product'].unique()
uniqueValues

uniqueValues = df['Geography'].unique()
uniqueValues

df.Product = df.Product.replace({"Hard coolers": "Hard Coolers", "Hard Cooler": "Hard Coolers"})

df['Period'] = pd.to_datetime(df['Period'])
df

estadisticos = df.describe()
estadisticos

"""### Preparacion de datos (Fase de preparacion de datos)
*En esta seccion se pretende realizar un menejo de datos NULL en los parametros que no permiten este tipo de datos. Para esto se realizara una transformacion de los datos categoricos para un mejor manejo y un areduccion de las carateristicas principales*

### Manejo de valores perdidos
Para manejar los valores Null aplicaremos la "lógica de relleno" seguida de la asignación de un valor por defecto para los valores nulos que puedan seguir existiendo, para asegurarnos de que todos ellos han sido sustituidos adecuadamente:
"""

#<Comentario> Seleccion de Caracteristicas (Features)  

print("Acontinucaiocn se muestran los estadisticos de las variables cuantitativas")
estadisticos = df.describe()

null_df = df.isnull().sum()
print("Numero de Null values en cada columna:\n{}".format(null_df))

df["Geography"].fillna("Not Geography", inplace = True)
df["Product"].fillna("Whitout Product", inplace = True)

"""### Variables numéricas"""

#<COMENTARIO>--- Variables numéricas
# ==============================================================================

for item, information in  df.groupby("VariableName"): 
  try:
    information["VariableVelue"] = information["VariableVelue"].astype(float)
    print(item, "\n{}".format(information.select_dtypes(include=['float64', 'int']).describe()))
  except:
    pass

  #information.plot(x="fecha", y= columnSum, marker="*", title = item, figsize=(15,4))

#<COMENTARIO>--- Variables numéricas
# ==============================================================================

for item, information in  df.groupby("VariableName"): 
  try:
    information["VariableVelue"] = information["VariableVelue"].astype(float)
    information.plot(x="Period", y= "VariableVelue", marker="*", title = item, figsize=(20,6))
  except:
    pass

"""### Variable respuesta
En este caso es posible ver que la variable respuesta es el numero de pares vendidos
"""

df_pivot = df.pivot_table(index = ["Geography",	"Period",	"Product"]	, 
                          columns='VariableName', values='VariableVelue', aggfunc=list)

df_pivot

def graficarDistribuciones (dataFrame, columna):
  """Grafica la variable obetivo decaurdo a distribuciones comunes"""
  dataFrame[columna].astype(float)
  fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(20, 10))
  sns.distplot(
      dataFrame[columna],
      hist    = False,
      rug     = True,
      color   = "blue",
      kde_kws = {'shade': True, 'linewidth': 1},
      ax      = axes[0]
  )
  axes[0].set_title("Distribución original-MENSUAL", fontsize = 'medium')
  axes[0].set_xlabel('pares', fontsize='small') 
  axes[0].tick_params(labelsize = 6)

  sns.distplot(
      np.sqrt(dataFrame[columna].astype(float)),
      hist    = False,
      rug     = True,
      color   = "blue",
      kde_kws = {'shade': True, 'linewidth': 1},
      ax      = axes[1]
  )
  axes[1].set_title("Transformación raíz cuadrada", fontsize = 'medium')
  axes[1].set_xlabel('sqrt(pares)', fontsize='small') 
  axes[1].tick_params(labelsize = 6)

  sns.distplot(
      np.log(dataFrame[columna].astype(float)),
      hist    = False,
      rug     = True,
      color   = "blue",
      kde_kws = {'shade': True, 'linewidth': 1},
      ax      = axes[2]
  )
  axes[2].set_title("Transformación logarítmica", fontsize = 'medium')
  axes[2].set_xlabel('log(pares)', fontsize='small') 
  axes[2].tick_params(labelsize = 6)

  fig.tight_layout()
  
graficarDistribuciones(df[df["VariableName"]=="sellthru_units"], "VariableVelue")

distribuciones = ['cauchy', 'chi2', 'expon',  'exponpow', 'gamma',
                  'norm', 'powerlaw', 'beta', 'logistic']

fitter = Fitter(df[df["VariableName"]=="sellthru_units"].VariableVelue.astype(float), distributions=distribuciones)
fitter.fit()
fitter.summary(Nbest=10, plot=False)
# APARECE EN ORDEN DE LA QUE MAS SE ASEMEJA A LA QUE MENOS

fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(25, 15))
axes = axes.flat
i = 0

for item, information in  df.groupby("VariableName"): 
  try:
    information["VariableVelue"] = information["VariableVelue"].astype(float)
  except:
    
    
    information["VariableVelue"].value_counts().plot.barh(ax = axes[i])
    axes[i].set_title(item, fontsize = 12, fontweight = "bold")
    axes[i].tick_params(labelsize = 11)
    axes[i].set_xlabel("")
    i = i+1
    
    
fig.tight_layout()
plt.subplots_adjust(top=0.9)
fig.suptitle('Distribución variables cualitativas',
             fontsize = 10, fontweight = "bold");